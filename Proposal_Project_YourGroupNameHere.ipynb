{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "https://github.com/kstad21/COGS188_jhek/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Katy Stadler\n",
    "- Elvin Li\n",
    "- Jiasheng Zhou\n",
    "- Harry Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "We propose to examine the effectiveness of several reinforcement learning strategies on the Tetris environment, including deep-Q networks, proximal policy optimization and Monte Carlo Tree Search. Within each RL strategy, we can explore different cost functions and other hyperparameters to gain information about optimal performance parameters for each learning method. To evaluate the overall performance of the algorithms, we will examine both the speed/rate of convergence and overall performance post-convergence, as well as compare the performance of our model to the performance of the benchmark agent given in the environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Tetris is a video game created by a Russian software engineer that became popular worldwide. In the game, there is a grid-environment where differently shaped blocks “fall” from the top of the grid to the bottom. It is the user’s job to arrange the blocks (by moving them left and right and/or rotating them) so that they can survive as long as possible without any of the blocks accumulating all the way to the top of the grid. Rows can be dissolved (therefore giving the user more space) if every single grid in a row is filled by any part of a block (a ‘tetris’ is a quadruple of rows filled and cleared at the same time) [<sup>[1]</sup>](#historyoftetrisnote). Strategy for the game involves trying to maximize the number of cleared rows and tetrises, especially when the goal is to receive as many points as possible. In the situation where the goal is to “stay alive” as long as possible, the main goal is to keep the highest block as low as possible, often by virtue of row-clearings and/or tetrises.\n",
    "\n",
    "A 2013 paper introduced the Arcade Learning Environment (ALE) [<sup>[2]</sup>](#alenote) that we plan to utilize in this project. ALE’s goal is to provide an interface to hundreds of Atari game environments, as well as methods to evaluate and compare approaches used to train agents in these games. There are different methods for feature construction and three simple baseline agents: Random, which picks a random action every frame, Const, which picks a single action throughout an episode, and Perturb, which selects a fixed action with a 95% probability and is uniformly random otherwise. \n",
    "\n",
    "It has been proven that even in an offline version of Tetris, it is NP-complete to “maximize the number of cleared rows, maximize the number of tetrises, minimize the maximum height of an occupied square, or maximize the number of pieces played before the game ends” [<sup>[3]</sup>](#nphardnote). These results held when players were restricted to only 2 rotation/translation moves before each piece drops in height, restricted piece sets, and with an infinitely tall gameboard. This is why we are interested in testing the performance of different models and hyperparameters as we train an agent to play the game.\n",
    "\n",
    "Even before the 2013 ALE was released, there were several attempts at training an agent to play Tetris. In 1996, Tsitsiklis & Van Roy used feature-based dynamic programming (number of holes and height of the highest column) to achieve a score of around 30 cleared lines on a 16x10 grid [<sup>[4]</sup>](#dpnote). In the same year, Bertsekas & Tsitsiklis added the height of each column and the difference in height between adjacent columns as features. They achieved a higher score of 2800 lines using lambda-policy iteration [<sup>[5]</sup>](#lambdaitnote). Later, even further features were added, including mean column height and the sum of the differences in adjacent column height. Least-squares policy iteration achieved an average score of between 1000 and 3000 lines [<sup>[6]</sup>](#leastsquaresitnote). \n",
    "\n",
    "Due to the design of Tetris, it doesn’t really make sense to have a reward function that gives rewards only at the end of the game. One TD(0)-Learning implementation uses linear combinations of weighted features, such as the value of the highest-used column, the average of the heights of all used columns, the number of holes between pieces at each given time, and the “quadratic unevenness” of the profile (which is a result of summing the squared values of the differences of neighboring columns) [<sup>[7]</sup>](#egreedynote). In order to reduce the state space, a constrained height difference between adjacent columns was used to encode each state. In this experiment, it was shown that lower values of ε were beneficial when using an epsilon-greedy policy.\n",
    "\n",
    "Tetris can also be modeled as a Markov Decision process if its state space is somehow reduced. Without reduction, a simple 20x10 board has 2200 ways to fill it and even with the requirement that no row be completely full, this is still (210 - 1)20. This 2022 paper’s [<sup>[8]</sup>](#mdpnote) most successful approach, “Fitted Value Iteration”, chose a small set of features and represented each state in terms of this set of features. This method was contingent upon “featurization” of the MDP and a small number of samples from the original state space needed to represent the state-value relationship. The article also found that the features Max-Height, Num-Holes, and Num-Covers were promising features when it came to training an agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once).  \n",
    "\n",
    "\n",
    "\n",
    "The goal of this project is to develop a deep learning model that translates hand-drawn sketches into images of a specific style, bridging the gap between abstract line drawings and visual representations. Sketches serve as simplified depictions of objects, often omitting texture, color, and intricate details. The challenge lies in transforming these sketches into images that not only preserve structural integrity but also adhere to a chosen style, whether it be photorealistic, in the style of Avatar, or any domain.\n",
    "\n",
    "This problem can be framed as a self-supervised learning task where the model learns a mapping function between the sketch domain and a target image domain. The model's effectiveness can be evaluated using various metrics. Structural Similarity Index (SSIM) measures the preservation of structural details, while Fréchet Inception Distance (FID) evaluates how closely generated images match the distribution of the target style. Learned Perceptual Image Patch Similarity (LPIPS) provides a perceptual assessment of similarity, ensuring that generated images align with human visual expectations. Additionally, retrieval-based metrics such as Recall@K can assess how accurately the model generates images that fit the intended domain. The problem is also replicable, as the datasets we chose like the Sketchy Database and style-specific datasets provide a consistent framework for training and evaluation.\n",
    "\n",
    "Several machine learning approaches can be used to address this problem in recent years. Conditional Generative Adversarial Networks (cGANs), such as Pix2Pix, can generate images conditioned on input sketches while ensuring they adhere to a specific style. Diffusion models, such as Stable Diffusion with ControlNet, offer fine-grained control over image synthesis by guiding the diffusion process based on sketch constraints. Autoencoder-based models, such as Variational Autoencoders (VAEs) or U-Nets, can learn meaningful representations of sketches and transform them into stylized outputs. Style transfer techniques can also be integrated to refine the generated images to better match a particular aesthetic. Each of these methods provides a unique approach to the problem, depending on the desired balance between fidelity to the sketch and adherence to the target style.\n",
    "\n",
    "This project aims to enhance sketch-to-style image translation by leveraging deep learning techniques to generate high-quality, stylized images from sketches. By investigating different modeling approaches and evaluating performance using rigorous metrics, we hope to develop an effective sketch-to-image translation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Since we hope to measure the learning algorithms’ development of strategies, using past data for our experiments doesn’t align with the current goal of measuring RL-strategy effectiveness. Instead, we will generate data dynamically through live simulations, allowing our models to learn through interaction with the environment. One such environment that can foster this is Farama’s tetris environment (https://gymnasium.farama.org/environments/atari/tetris/), which provides a retro Tetris setup for reinforcement learning research. Training models in this environment is analogous to collecting data, as the agent improves its actions and policies through multiple iterations of gameplay, guided by a reward system (e.g. based on the number of rows cleared per episode). The environment offers a discrete action space with five possible moves: move left, move right, drop down, rotate, and no operation (NOOP). The game state is represented through an interface that can be launched in Python, with observations encoded as RGB pixel values.\n",
    "\n",
    "If we have time to expand on the current topic, we plan to introduce a neural network model that could theoretically learn from professional-level tetris gameplay, but this is currently out of scope for our proposed question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Why might your solution work? Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first begin by finding a large dataset of images with a similar drawing style, such as the above Avatar the Last Airbender dataset. We will then apply Sobel Edge Detection to create image pairs of edge images and ground truth images. This will either be done through the OpenCV Python library or our own implementation. Before being fed into our model, the images will be preprocessed and normalized to be 256x256 pixels (or whatever image size we find works best) and to have pixel values between (0,0,0) and (1,1,1) (for color). \n",
    "\n",
    "For our actual model implementation, we will utilize a Generative Adversarial Network (GAN) approach, where two neural networks will be competing against each other: One being a generator, and the other being a discriminator. Following the standard setup, the two networks will compete with each other (in a process akin to the minimax algorithm discussed in class). The generator will seek to maximize the objective of creating photorealistic images, while the discriminator will attempt to differentiate between real and fake images. Although we will experiment with different deep-learning models for the neural networks themselves, we will likely take a convolutional neural network (CNN) approach for this project, due to the success CNN-based models have had with other image-based machine learning tasks. After training, the generator should be able to produce suitably similar images to the given dataset, provided any starting sketch. We will build each neural network through either the pyTorch or Tensorflow/Keras frameworks, as that is what most of the members have experience in. \n",
    "\n",
    "The final images will be evaluated using Frechet Inception Distance or Structural Similarity Index, as discussed below. For robustness, we will use our proposed solution with several different datasets, and evaluate the final output models/images for each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).  \n",
    "\n",
    "\n",
    "To evaluate the performance of both the benchmark and solution models for sketch-to-style translation, Fréchet Inception Distance (FID) and Structural Similarity Index (SSIM) can be used. FID measures how similar the distribution of generated images is to real images by computing the Fréchet distance between their feature representations in a pretrained Inception network. It is defined as:\n",
    "\n",
    "$$\n",
    "FID = ||\\mu_r - \\mu_g||^2 + \\text{Tr}(\\Sigma_r + \\Sigma_g - 2\\sqrt{\\Sigma_r \\Sigma_g})\n",
    "$$\n",
    "\n",
    "where $\\mu_r, \\Sigma_r$ are the mean and covariance of real images, and $\\mu_g, \\Sigma_g$ are for generated images. Lower FID indicates that the generated images better match the target style. SSIM, on the other hand, evaluates pixel-wise structural similarity and is given by:\n",
    "\n",
    "$$\n",
    "SSIM(x, y) = \\frac{(2\\mu_x \\mu_y + C_1)(2\\sigma_{xy} + C_2)}{(\\mu_x^2 + \\mu_y^2 + C_1)(\\sigma_x^2 + \\sigma_y^2 + C_2)}\n",
    "$$\n",
    "\n",
    "where $\\mu_x, \\mu_y$ are mean intensities, $\\sigma_x^2, \\sigma_y^2$ are variances, and $\\sigma_{xy}$ is the covariance. Higher SSIM values indicate greater structural similarity between the generated and reference images. FID captures perceptual quality and style consistency, while SSIM ensures structural integrity, making them complementary for evaluating the effectiveness of the model in preserving sketch details while achieving the desired style transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination. Get creative!\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One potential ethical concern involving this project would be the impact it has on actual artists, as the model we aim to develop would imitate existing drawings. We can break this down into 3 overarching issues, those being the issues of copyright and privacy infringements with the training data, the potential for misuse through plagiarism or fraudulent images, and the effect the model might have in competing with existing art. \n",
    "\n",
    "1. If the model is trained on copyrighted images, that would be an infringement of intellectual property. Furthermore, if the training data contains images that a person may have wanted to keep private, then that would be an invasion of privacy as well. To mitigate this issue, we will try our best to look for public datasets with a Creative Commons License, as that license would ensure that the images within have been approved for our intended usage. By focusing on large, publicly sourced datasets, we will also likely avoid using any private images, although that may not be guaranteed.\n",
    "2. If a user uses the model to create artwork and then attempts to pass it off as their own, it may constitute as plagiarism and would be breach of integrity depending on what the artwork is used for. For example, submitting AI-generated work as original content in art competitions, academic settings, or commissioned projects could mislead others and devalue genuine artistic effort. Additionally, fraudulent images created by the model could be used with intent to deceive or harm other people, through attacking their images or portraying something untruthful. To avoid this issue, we could add a small watermark to every image to mark it as AI-generated, making it more apparent if someone attempts to pass it off as their own work or with intent to harm others.\n",
    "3. The third ethical concern involves the broader impact the model might have on artists and the art community. By automating the process of turning sketches into detailed images, this tool could diminish the demand for professional artists or undervalue the time and skill required to create original artwork. Emerging or independent artists might struggle to compete against these AI image generators, undermining their work. Again, to avoid this issue, adding a small watermark may help to clarify the origin of the artwork."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Communications through group chat via Instagram and email. Expected to be addressed within 24 hours.*\n",
    "* *We will create a schedule on sheets to keep track of course deadlines and self-set deadlines, with assignments for a specific member if applicable.*\n",
    "* *It is understand that members may have different strengths/expertise, and it is expected that everyone contributes substantially to the project so that the work is evenly divided.*\n",
    "* *Team or scheduling issues will be addressed in a group meeting, either in person or via Zoom. We prefer for in-depth issues to be discussed face-to-face.*\n",
    "* *Week-to-week goals will be set and there will be weekly checkins to update the spreadsheet and check in on progress.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 3/04  |  12 PM | Complete proposal with new topic  | Resubmit proposal to Scott | \n",
    "| 3/08  |  6 PM |  Get a simple Q-learning model to train, each person should also get the environment working and investigate | Things that worked and things that didn't work; next steps | \n",
    "| 3/12  | 6:30 PM  | Implement more of the models  | Discuss any problems and possible ways to refine the models |\n",
    "| 3/16  | 6:30 PM  | Refine models and evaluation metrics | Make sure work is combined seamlessly  |\n",
    "| 3/17  | 6:30 PM  | Next steps to start report | Delegate work for report |\n",
    "| 3/19  | 6:30 PM  | Have the writeup done before the due date | Use the extra time to check over the writeup  |\n",
    "| 3/19  | 11:15 PM  | Turn it in!  | N/A |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<!--\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n",
    "-->\n",
    "\n",
    "<a id=\"historyoftetrisnote\"></a>  \n",
    "**¹** Weisberger, M. (13 Oct 2016) The Bizarre History of 'Tetris'. *LiveScience*. https://www.livescience.com/56481-strange-history-of-tetris.html <br>\n",
    "<a id=\"alenote\"></a> **²** Bellemare, M. et al. (14 Jun 2013) The Arcade Learning Environment: An Evaluation Platform for General Agents. *Journal of Artificial Intelligence Research*. https://jair.org/index.php/jair/article/view/10819 <br>\n",
    "<a id=\"nphardnote\"></a> **³** Demaine, E. et al. (21 Oct 2002) Tetris is Hard, Even to Approximate. arXiv.org. https://arxiv.org/abs/cs/0210020 <br>\n",
    "<a id=\"dpnote\"></a> **⁴** Tsitsiklis, J., Van Roy, B. (5 May 1996) An Analysis of Temporal-Difference Learning with Function Approximation. *IEEE TRANSACTIONS ON AUTOMATIC CONTROL*. https://www.mit.edu/~jnt/Papers/J063-97-bvr-td.pdf <br>\n",
    "<a id=\"lambdaitnote\"></a> **⁵** Bertsekas, D., Tsitsiklis, J. (1996) Neuro-Dynamic Programming. *Athena Scientific* <br>\n",
    "<a id=\"leastsquaresitnote\"></a> **⁶** Lagoudakis, M. et al. (2002) Least-squares methods in reinforcement learning for control. *Hellenic Conference on Artificial Intelligence* <br>\n",
    "<a id=\"egreedynote\"></a> **⁷** Thiam, P. et al. (2014) A Reinforcement Learning Algorithm to Train a Tetris Playing Agent. *Artificial Neural Networks in Pattern Recognition*. https://link.springer.com/chapter/10.1007/978-3-319-11656-3_15 <br>\n",
    "<a id=\"mdpnote\"></a> **⁸** Bodoia, M., Puranik, A. (2022) Applying Reinforcement Learning to Competitive Tetris. https://cs229.stanford.edu/proj2012/BodoiaPuranik-ApplyingReinforcementLearningToCompetitiveTetris.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
